{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spectral'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m shuffle\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspectral\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mndimage\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rotate\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spectral'"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import random\n",
    "import spectral\n",
    "import scipy.ndimage\n",
    "from skimage.transform import rotate\n",
    "import os\n",
    "import patch_size\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset\n",
    "==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(os.getcwd(),\"Data\")\n",
    "input_mat = scipy.io.loadmat(os.path.join(DATA_PATH, 'Indian_pines.mat'))['indian_pines']\n",
    "target_mat = scipy.io.loadmat(os.path.join(DATA_PATH, 'Indian_pines_gt.mat'))['indian_pines_gt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define global variables\n",
    "======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HEIGHT = input_mat.shape[0]\n",
    "WIDTH = input_mat.shape[1]\n",
    "BAND = input_mat.shape[2]\n",
    "PATCH_SIZE = patch_size.patch_size\n",
    "TRAIN_PATCH,TRAIN_LABELS,TEST_PATCH,TEST_LABELS = [],[],[],[]\n",
    "CLASSES = [] \n",
    "COUNT = 200 #Number of patches of each class\n",
    "OUTPUT_CLASSES = 16\n",
    "TEST_FRAC = 0.25 #Fraction of data to be used for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Scale the input between [0,1]\n",
    "=========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_mat = input_mat.astype(float)\n",
    "input_mat -= np.min(input_mat)\n",
    "input_mat /= np.max(input_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the mean of each channel for normalization\n",
    "===================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MEAN_ARRAY = np.ndarray(shape=(BAND,),dtype=float)\n",
    "for i in range(BAND):\n",
    "    MEAN_ARRAY[i] = np.mean(input_mat[:,:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Patch(height_index,width_index):\n",
    "    \"\"\"\n",
    "    Returns a mean-normalized patch, the top left corner of which \n",
    "    is at (height_index, width_index)\n",
    "    \n",
    "    Inputs: \n",
    "    height_index - row index of the top left corner of the image patch\n",
    "    width_index - column index of the top left corner of the image patch\n",
    "    \n",
    "    Outputs:\n",
    "    mean_normalized_patch - mean normalized patch of size (PATCH_SIZE, PATCH_SIZE) \n",
    "    whose top left corner is at (height_index, width_index)\n",
    "    \"\"\"\n",
    "    transpose_array = np.transpose(input_mat,(2,0,1))\n",
    "    height_slice = slice(height_index, height_index+PATCH_SIZE)\n",
    "    width_slice = slice(width_index, width_index+PATCH_SIZE)\n",
    "    patch = transpose_array[:, height_slice, width_slice]\n",
    "    mean_normalized_patch = []\n",
    "    for i in range(patch.shape[0]):\n",
    "        mean_normalized_patch.append(patch[i] - MEAN_ARRAY[i]) \n",
    "    \n",
    "    return np.array(mean_normalized_patch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Collect all available patches of each class from the given image\n",
    "================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(OUTPUT_CLASSES):\n",
    "    CLASSES.append([])\n",
    "for i in range(HEIGHT - PATCH_SIZE + 1):\n",
    "    for j in range(WIDTH - PATCH_SIZE + 1):\n",
    "        curr_inp = Patch(i,j)\n",
    "        curr_tar = target_mat[i + int((PATCH_SIZE - 1)/2), j + int((PATCH_SIZE - 1)/2)]\n",
    "        if(curr_tar!=0): #Ignore patches with unknown landcover type for the central pixel\n",
    "            CLASSES[curr_tar-1].append(curr_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "1378\n",
      "547\n",
      "152\n",
      "340\n",
      "730\n",
      "28\n",
      "356\n",
      "20\n",
      "843\n",
      "2245\n",
      "481\n",
      "205\n",
      "1095\n",
      "142\n",
      "93\n"
     ]
    }
   ],
   "source": [
    "for c  in CLASSES:\n",
    "    print(len(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a test split with 25% data from each class\n",
    "==============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in range(OUTPUT_CLASSES): #for each class\n",
    "    class_population = len(CLASSES[c])\n",
    "    test_split_size = int(class_population*TEST_FRAC)\n",
    "        \n",
    "    patches_of_current_class = CLASSES[c]\n",
    "    shuffle(patches_of_current_class)\n",
    "    \n",
    "    #Make training and test splits\n",
    "    TRAIN_PATCH.append(patches_of_current_class[:-test_split_size])\n",
    "        \n",
    "    TEST_PATCH.extend(patches_of_current_class[-test_split_size:])\n",
    "    TEST_LABELS.extend(np.full(test_split_size, c, dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "1034\n",
      "411\n",
      "114\n",
      "255\n",
      "548\n",
      "21\n",
      "267\n",
      "15\n",
      "633\n",
      "1684\n",
      "361\n",
      "154\n",
      "822\n",
      "107\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "for c in TRAIN_PATCH:\n",
    "    print(len(c))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversample the classes which do not have at least COUNT patches in the training set and extract COUNT patches\n",
    "============================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(OUTPUT_CLASSES):\n",
    "    if(len(TRAIN_PATCH[i])<COUNT):\n",
    "        tmp = TRAIN_PATCH[i]\n",
    "        for j in range(int(COUNT/len(TRAIN_PATCH[i]))):\n",
    "            shuffle(TRAIN_PATCH[i])\n",
    "            TRAIN_PATCH[i] = TRAIN_PATCH[i] + tmp\n",
    "    shuffle(TRAIN_PATCH[i])\n",
    "    TRAIN_PATCH[i] = TRAIN_PATCH[i][:COUNT]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "for c in TRAIN_PATCH:\n",
    "    print(len(c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_PATCH = np.asarray(TRAIN_PATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_PATCH = TRAIN_PATCH.reshape((-1,220,PATCH_SIZE,PATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_LABELS = np.array([])\n",
    "for l in range(OUTPUT_CLASSES):\n",
    "    TRAIN_LABELS = np.append(TRAIN_LABELS, np.full(COUNT, l, dtype=int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment the data with random flipped and rotated patches\n",
    "========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for i in range(OUTPUT_CLASSES):\n",
    "#     shuffle(CLASSES[i])\n",
    "#     for j in range(COUNT/2): #There will be COUNT/2 original patches and COUNT/2 randomly rotated/flipped patches of each class\n",
    "#         num = random.randint(0,2)\n",
    "#         if num == 0 :\n",
    "#             flipped_patch = np.flipud(CLASSES[i][j]) #Flip patch up-down\n",
    "#         if num == 1 :\n",
    "#             flipped_patch = np.fliplr(CLASSES[i][j]) #Flip patch left-right\n",
    "#         if num == 2 :\n",
    "#             no = random.randrange(-180,180,30)\n",
    "#             flipped_patch = scipy.ndimage.interpolation.rotate(CLASSES[i][j], no,axes=(1, 0), \n",
    "#                     reshape=False, output=None, order=3, mode='constant', cval=0.0, prefilter=False) #Rotate patch by a random angle\n",
    "#         TRAIN_PATCH.append(CLASSES[i][j])\n",
    "#         TRAIN_LABELS.append(i)\n",
    "#         TRAIN_PATCH.append(flipped_patch)\n",
    "#         TRAIN_LABELS.append(i)\n",
    "\n",
    "#     for j in range(COUNT/2,COUNT/2 + 100):\n",
    "#         num = random.randint(0,2)\n",
    "#         if num == 0 :\n",
    "#             flipped_patch = np.flipud(CLASSES[i][j])\n",
    "#         if num == 1 :\n",
    "#             flipped_patch = np.fliplr(CLASSES[i][j])\n",
    "#         if num == 2 :\n",
    "#             no = random.randrange(-180,180,30)\n",
    "#             flipped_patch = scipy.ndimage.interpolation.rotate(CLASSES[i][j], no, axes=(1, 0), reshape=False, output=None, order=3, mode='constant', cval=0.0, prefilter=False)\n",
    "#         TEST_PATCH.append(CLASSES[i][j])\n",
    "#         TEST_LABELS.append(i)\n",
    "#         TEST_PATCH.append(flipped_patch)\n",
    "#         TEST_LABELS.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2170\n",
      "3200\n"
     ]
    }
   ],
   "source": [
    "print (len(TEST_PATCH))\n",
    "print (len(TRAIN_PATCH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the patches in segments\n",
    "================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Training data\n",
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "for i in range(int(len(TRAIN_PATCH)/(COUNT*2))):\n",
    "    train_dict = {}\n",
    "    start = i * (COUNT*2)\n",
    "    end = (i+1) * (COUNT*2)\n",
    "    file_name = 'Train_'+str(PATCH_SIZE)+'_'+str(i+1)+'.mat'\n",
    "    train_dict[\"train_patch\"] = TRAIN_PATCH[start:end]\n",
    "    train_dict[\"train_labels\"] = TRAIN_LABELS[start:end]\n",
    "    scipy.io.savemat(os.path.join(DATA_PATH, file_name),train_dict)\n",
    "    print(i),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Test data\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(int(len(TEST_PATCH)/(COUNT*2))):\n",
    "    test_dict = {}\n",
    "    start = i * (COUNT*2)\n",
    "    end = (i+1) * (COUNT*2)\n",
    "    file_name = 'Test_'+str(PATCH_SIZE)+'_'+str(i+1)+'.mat'\n",
    "    test_dict[\"test_patch\"] = TEST_PATCH[start:end]\n",
    "    test_dict[\"test_labels\"] = TEST_LABELS[start:end]\n",
    "    scipy.io.savemat(os.path.join(DATA_PATH, file_name),test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TRAIN_PATCH)/(COUNT*2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
