{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trains and Evaluates the IndianPines network using a feed dictionary\n",
    "========================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Srivatsa\\AppData\\Local\\Temp\\ipykernel_14032\\439292361.py:14: The name tf.disable_v2_behavior is deprecated. Please use tf.compat.v1.disable_v2_behavior instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Srivatsa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "2.19.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "def dummy_npwarn_decorator_factory():\n",
    "  def npwarn_decorator(x):\n",
    "    return x\n",
    "  return npwarn_decorator\n",
    "np._no_nep50_warning = getattr(np, '_no_nep50_warning', dummy_npwarn_decorator_factory)\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "print (tf.__version__)\n",
    "import os\n",
    "import IndianPinesCNN \n",
    "import patch_size\n",
    "# import IndianPines_data_set as input_data\n",
    "import Spatial_dataset as input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare model parameters as external flags\n",
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# flags = tf.app.flags\n",
    "# FLAGS = flags.FLAGS\n",
    "# flags.DEFINE_float('learning_rate', 0.01, 'Initial learning rate.')\n",
    "# flags.DEFINE_integer('max_steps', 4000, 'Number of steps to run trainer.')\n",
    "# flags.DEFINE_integer('conv1', 500, 'Number of filters in convolutional layer 1.')\n",
    "# flags.DEFINE_integer('conv2', 100, 'Number of filters in convolutional layer 2.')\n",
    "# flags.DEFINE_integer('hidden1', 200, 'Number of units in hidden layer 1.')\n",
    "# flags.DEFINE_integer('hidden2', 84, 'Number of units in hidden layer 2.')\n",
    "# flags.DEFINE_integer('batch_size', 100, 'Batch size.  '\n",
    "#                      'Must divide evenly into the dataset sizes.')\n",
    "# # flags.DEFINE_string('train_dir', '1.mat', 'Directory to put the training data.')\n",
    "\n",
    "learning_rate = 0.01  # Initial learning rate\n",
    "max_steps = 4000  # Number of steps to run trainer\n",
    "conv1 = 500  # Number of filters in convolutional layer 1\n",
    "conv2 = 100  # Number of filters in convolutional layer 2\n",
    "hidden1 = 200  # Number of units in hidden layer 1\n",
    "hidden2 = 84  # Number of units in hidden layer 2\n",
    "batch_size = 100  # Batch size\n",
    "\n",
    "# import argparse\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--learning_rate', type=float, default=0.01, help='Initial learning rate.')\n",
    "# parser.add_argument('--max_steps', type=int, default=4000, help='Number of steps to run trainer.')\n",
    "# parser.add_argument('--conv1', type=int, default=500, help='Number of filters in convolutional layer 1.')\n",
    "# parser.add_argument('--conv2', type=int, default=100, help='Number of filters in convolutional layer 2.')\n",
    "# parser.add_argument('--hidden1', type=int, default=200, help='Number of units in hidden layer 1.')\n",
    "# parser.add_argument('--hidden2', type=int, default=84, help='Number of units in hidden layer 2.')\n",
    "# parser.add_argument('--batch_size', type=int, default=100, help='Batch size.')\n",
    "\n",
    "# FLAGS, _ = parser.parse_known_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_epochs = 20\n",
    "max_steps = 4000\n",
    "IMAGE_SIZE = patch_size.patch_size\n",
    "conv1 = 500\n",
    "conv2 = 100\n",
    "fc1 = 200,\n",
    "fc2 = 84\n",
    "batch_size = 100\n",
    "TRAIN_FILES = 8\n",
    "TEST_FILES = 4\n",
    "DATA_PATH = os.path.join(os.getcwd(),\"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def placeholder_inputs(batch_size):\n",
    "    \"\"\"Generate placeholder variables to represent the input tensors.\n",
    "    These placeholders are used as inputs by the rest of the model building\n",
    "    code and will be fed from the downloaded data in the .run() loop, below.\n",
    "    Args:\n",
    "    batch_size: The batch size will be baked into both placeholders.\n",
    "    Returns:\n",
    "    images_placeholder: Images placeholder.\n",
    "    labels_placeholder: Labels placeholder.\n",
    "    \"\"\"\n",
    "    # Note that the shapes of the placeholders match the shapes of the full\n",
    "    # image and label tensors, except the first dimension is now batch_size\n",
    "    # rather than the full size of the train or test data sets.\n",
    "    images_placeholder = tf.placeholder(tf.float32, shape=(batch_size, IndianPinesCNN\n",
    "                                                           .IMAGE_PIXELS))\n",
    "    labels_placeholder = tf.placeholder(tf.int32, shape=(batch_size))\n",
    "    return images_placeholder, labels_placeholder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_feed_dict(data_set, images_pl, labels_pl):\n",
    "    \"\"\"Fills the feed_dict for training the given step.\n",
    "    A feed_dict takes the form of:\n",
    "    feed_dict = {\n",
    "      <placeholder>: <tensor of values to be passed for placeholder>,\n",
    "      ....\n",
    "    }\n",
    "    Args:\n",
    "    data_set: The set of images and labels, from input_data.read_data_sets()\n",
    "    images_pl: The images placeholder, from placeholder_inputs().\n",
    "    labels_pl: The labels placeholder, from placeholder_inputs().\n",
    "    Returns:\n",
    "    feed_dict: The feed dictionary mapping from placeholders to values.\n",
    "    \"\"\"\n",
    "    # Create the feed_dict for the placeholders filled with the next\n",
    "    # `batch size ` examples.\n",
    "    images_feed, labels_feed = data_set.next_batch(batch_size)\n",
    "    feed_dict = {\n",
    "      images_pl: images_feed,\n",
    "      labels_pl: labels_feed,\n",
    "    }\n",
    "    return feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_eval(sess,\n",
    "            eval_correct,\n",
    "            images_placeholder,\n",
    "            labels_placeholder,\n",
    "            data_set):\n",
    "    \"\"\"Runs one evaluation against the full epoch of data.\n",
    "    Args:\n",
    "    sess: The session in which the model has been trained.\n",
    "    eval_correct: The Tensor that returns the number of correct predictions.\n",
    "    images_placeholder: The images placeholder.\n",
    "    labels_placeholder: The labels placeholder.\n",
    "    data_set: The set of images and labels to evaluate, from\n",
    "      input_data.read_data_sets().\n",
    "    \"\"\"\n",
    "    # And run one epoch of eval.\n",
    "    true_count = 0  # Counts the number of correct predictions.\n",
    "    steps_per_epoch = data_set.num_examples // batch_size\n",
    "    num_examples = steps_per_epoch * batch_size\n",
    "    for step in xrange(steps_per_epoch):\n",
    "        feed_dict = fill_feed_dict(data_set,\n",
    "                                   images_placeholder,\n",
    "                                   labels_placeholder)\n",
    "        true_count += sess.run(eval_correct, feed_dict=feed_dict)\n",
    "    precision = true_count / num_examples\n",
    "    print('  Num examples: %d  Num correct: %d  Precision @ 1: %0.04f' %\n",
    "        (num_examples, true_count, precision))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_DataSet(first,second):\n",
    "    temp_image = np.concatenate((first.images,second.images),axis=0)\n",
    "    temp_labels = np.concatenate((first.labels,second.labels),axis=0)\n",
    "    temp_image = temp_image.reshape(temp_image.shape[0],IMAGE_SIZE,IMAGE_SIZE,220)\n",
    "    temp_image = np.transpose(temp_image,(0,3,1,2))\n",
    "    temp_labels = np.transpose(temp_labels)\n",
    "    return input_data.DataSet(temp_image,temp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_training():\n",
    "    \"\"\"Train MNIST for a number of steps.\"\"\"\n",
    "    # Get the sets of images and labels for training, validation, and\n",
    "    # test on IndianPines.\n",
    "    \n",
    "    \"\"\"Concatenating all the training and test mat files\"\"\"\n",
    "    for i in range(TRAIN_FILES):\n",
    "        data_sets = input_data.read_data_sets(os.path.join(DATA_PATH, 'Train_'+str(IMAGE_SIZE)+'_'+str(i+1)+'.mat'), 'train')\n",
    "        if(i==0):\n",
    "            Training_data = data_sets\n",
    "            continue\n",
    "        else:\n",
    "            Training_data = add_DataSet(Training_data,data_sets)\n",
    "            \n",
    "    for i in range(TEST_FILES):\n",
    "        data_sets = input_data.read_data_sets(os.path.join(DATA_PATH, 'Test_'+str(IMAGE_SIZE)+'_'+str(i+1)+'.mat'),'test')\n",
    "        if(i==0):\n",
    "            Test_data = data_sets\n",
    "            continue\n",
    "        else:\n",
    "            Test_data = add_DataSet(Test_data,data_sets)\n",
    "        \n",
    "    # Tell TensorFlow that the model will be built into the default Graph.\n",
    "    with tf.Graph().as_default():\n",
    "    # Generate placeholders for the images and labels.\n",
    "        images_placeholder, labels_placeholder = placeholder_inputs(batch_size)\n",
    "\n",
    "        # Build a Graph that computes predictions from the inference model.\n",
    "        logits = IndianPinesCNN.inference(images_placeholder,\n",
    "                                 conv1,\n",
    "                                 conv2,        \n",
    "                                 hidden1,\n",
    "                                 hidden2)\n",
    "\n",
    "        # Add to the Graph the Ops for loss calculation.\n",
    "        loss = IndianPinesCNN.loss(logits, labels_placeholder)\n",
    "\n",
    "        # Add to the Graph the Ops that calculate and apply gradients.\n",
    "        train_op = IndianPinesCNN.training(loss, learning_rate)\n",
    "\n",
    "        # Add the Op to compare the logits to the labels during evaluation.\n",
    "        eval_correct = IndianPinesCNN.evaluation(logits, labels_placeholder)\n",
    "\n",
    "        # Build the summary operation based on the TF collection of Summaries.\n",
    "    #    summary_op = tf.merge_all_summaries()\n",
    "\n",
    "        # Add the variable initializer Op.\n",
    "        init = tf.initialize_all_variables()\n",
    "\n",
    "        # Create a saver for writing training checkpoints.\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        # Create a session for running Ops on the Graph.\n",
    "        sess = tf.Session()\n",
    "\n",
    "        # Instantiate a SummaryWriter to output summaries and the Graph.\n",
    "    #    summary_writer = tf.train.SummaryWriter(Ftrain_dir, sess.graph)\n",
    "\n",
    "        # And then after everything is built:\n",
    "\n",
    "        # Run the Op to initialize the variables.\n",
    "        sess.run(init)\n",
    "\n",
    "        # Start the training loop.\n",
    "        for step in xrange(max_steps):\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Fill a feed dictionary with the actual set of images and labels\n",
    "            # for this particular training step.\n",
    "            feed_dict = fill_feed_dict(Training_data,\n",
    "                                     images_placeholder,\n",
    "                                     labels_placeholder)\n",
    "\n",
    "            # Run one step of the model.  The return values are the activations\n",
    "            # from the `train_op` (which is discarded) and the `loss` Op.  To\n",
    "            # inspect the values of your Ops or variables, you may include them\n",
    "            # in the list passed to sess.run() and the value tensors will be\n",
    "            # returned in the tuple from the call.\n",
    "            _, loss_value = sess.run([train_op, loss],\n",
    "                                   feed_dict=feed_dict)\n",
    "\n",
    "            duration = time.time() - start_time\n",
    "\n",
    "            # Write the summaries and print an overview fairly often.\n",
    "            if step % 50 == 0:\n",
    "            # Print status to stdout.\n",
    "                print('Step %d: loss = %.2f (%.3f sec)' % (step, loss_value, duration))\n",
    "            # Update the events file.\n",
    "                # summary_str = sess.run(summary_op, feed_dict=feed_dict)\n",
    "                # summary_writer.add_summary(summary_str, step)\n",
    "                # summary_writer.flush()\n",
    "\n",
    "            # Save a checkpoint and evaluate the model periodically.\n",
    "            if (step + 1) % 1000 == 0 or (step + 1) == max_steps:\n",
    "                saver.save(sess, 'model-spatial-CNN-'+str(IMAGE_SIZE)+'X'+str(IMAGE_SIZE)+'.ckpt', global_step=step)\n",
    "\n",
    "            # Evaluate against the training set.\n",
    "                print('Training Data Eval:')\n",
    "                do_eval(sess,\n",
    "                        eval_correct,\n",
    "                        images_placeholder,\n",
    "                        labels_placeholder,\n",
    "                        Training_data)\n",
    "                print('Test Data Eval:')\n",
    "                do_eval(sess,\n",
    "                        eval_correct,\n",
    "                        images_placeholder,\n",
    "                        labels_placeholder,\n",
    "                        Test_data)\n",
    "            # Evaluate against the validation set.\n",
    "    #             print('Validation Data Eval:')\n",
    "    #             do_eval(sess,\n",
    "    #                     eval_correct,\n",
    "    #                     images_placeholder,\n",
    "    #                     labels_placeholder,\n",
    "    #                     data_sets.validation)\n",
    "    #             # Evaluate against the test set.\n",
    "    #             print('Test Data Eval:')\n",
    "    #             do_eval(sess,\n",
    "    #                     eval_correct,\n",
    "    #                     images_placeholder,\n",
    "    #                     labels_placeholder,\n",
    "    #                     data_sets.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "def run_training_with_cross_validation(k_folds=5):\n",
    "    \"\"\"\n",
    "    Train the CNN model using K-Fold Cross-Validation.\n",
    "    \"\"\"\n",
    "    # Load the full dataset (training + testing combined)\n",
    "    full_data_images = []\n",
    "    full_data_labels = []\n",
    "    \n",
    "    # Concatenate all training and test files into a single dataset\n",
    "    for i in range(TRAIN_FILES):\n",
    "        data_sets = input_data.read_data_sets(os.path.join(DATA_PATH, f'Train_{IMAGE_SIZE}_{i+1}.mat'), 'train')\n",
    "        full_data_images.append(data_sets.images)\n",
    "        full_data_labels.append(data_sets.labels)\n",
    "    \n",
    "    for i in range(TEST_FILES):\n",
    "        data_sets = input_data.read_data_sets(os.path.join(DATA_PATH, f'Test_{IMAGE_SIZE}_{i+1}.mat'), 'test')\n",
    "        full_data_images.append(data_sets.images)\n",
    "        full_data_labels.append(data_sets.labels)\n",
    "    \n",
    "    # Combine all images and labels\n",
    "    full_data_images = np.concatenate(full_data_images, axis=0)\n",
    "    full_data_labels = np.concatenate(full_data_labels, axis=0)\n",
    "\n",
    "    # full_data_labels = full_data_labels.flatten()\n",
    "    \n",
    "    # Reshape and preprocess the images\n",
    "    full_data_images = full_data_images.reshape(full_data_images.shape[0], IMAGE_SIZE, IMAGE_SIZE, 220)\n",
    "    full_data_images = np.transpose(full_data_images, (0, 3, 1, 2))  # Transpose to match input format\n",
    "    \n",
    "    # Initialize K-Fold Cross-Validation\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    fold_accuracies = []\n",
    "    \n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(full_data_images)):\n",
    "        print(f\"\\nStarting Fold {fold + 1}/{k_folds}\")\n",
    "        \n",
    "        # Split the data into training and validation sets\n",
    "        train_images, val_images = full_data_images[train_index], full_data_images[val_index]\n",
    "        train_labels, val_labels = full_data_labels[train_index], full_data_labels[val_index]\n",
    "        \n",
    "        # Create DataSet objects for training and validation\n",
    "        Training_data = input_data.DataSet(train_images, train_labels)\n",
    "        Validation_data = input_data.DataSet(val_images, val_labels)\n",
    "        \n",
    "        # Build the TensorFlow graph\n",
    "        with tf.Graph().as_default():\n",
    "            images_placeholder, labels_placeholder = placeholder_inputs(batch_size)\n",
    "            logits = IndianPinesCNN.inference(images_placeholder, conv1, conv2, hidden1, hidden2)\n",
    "            loss = IndianPinesCNN.loss(logits, labels_placeholder)\n",
    "            train_op = IndianPinesCNN.training(loss, learning_rate)\n",
    "            eval_correct = IndianPinesCNN.evaluation(logits, labels_placeholder)\n",
    "            init = tf.global_variables_initializer()\n",
    "            saver = tf.train.Saver()\n",
    "            \n",
    "            with tf.Session() as sess:\n",
    "                sess.run(init)\n",
    "                \n",
    "                # Training loop\n",
    "                for step in range(max_steps):\n",
    "                    feed_dict = fill_feed_dict(Training_data, images_placeholder, labels_placeholder)\n",
    "                    _, loss_value = sess.run([train_op, loss], feed_dict=feed_dict)\n",
    "                    \n",
    "                    if step % 50 == 0:\n",
    "                        print(f\"Step {step}: loss = {loss_value:.2f}\")\n",
    "                \n",
    "                # Evaluate on the validation set\n",
    "                print(\"Validation Data Eval:\")\n",
    "                true_count = 0\n",
    "                steps_per_epoch = Validation_data.num_examples // batch_size\n",
    "                num_examples = steps_per_epoch * batch_size\n",
    "                \n",
    "                for step in range(steps_per_epoch):\n",
    "                    feed_dict = fill_feed_dict(Validation_data, images_placeholder, labels_placeholder)\n",
    "                    true_count += sess.run(eval_correct, feed_dict=feed_dict)\n",
    "                \n",
    "                accuracy = true_count / num_examples\n",
    "                print(f\"Fold {fold + 1} Accuracy: {accuracy:.4f}\")\n",
    "                fold_accuracies.append(accuracy)\n",
    "    \n",
    "    # Print the average accuracy across all folds\n",
    "    print(f\"\\nCross-Validation Accuracy: {np.mean(fold_accuracies):.4f} ± {np.std(fold_accuracies):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv_1/Conv2D:0\", shape=(100, 19, 19, 500), dtype=float32)\n",
      "WARNING:tensorflow:From c:\\Users\\Srivatsa\\OneDrive\\Desktop\\Major Project\\Hyperspectral-master\\Hyperspectral-master\\IndianPinesCNN.py:76: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Tensor(\"h_conv2/h_conv2:0\", shape=(100, 8, 8, 100), dtype=float32)\n",
      "Tensor(\"h_pool2:0\", shape=(100, 4, 4, 100), dtype=float32)\n",
      "Tensor(\"Reshape:0\", shape=(100, 1600), dtype=float32)\n",
      "WARNING:tensorflow:From C:\\Users\\Srivatsa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From c:\\Users\\Srivatsa\\OneDrive\\Desktop\\Major Project\\Hyperspectral-master\\Hyperspectral-master\\IndianPinesCNN.py:176: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Srivatsa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\training\\adagrad.py:138: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Srivatsa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:288: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Step 0: loss = 2.74 (0.736 sec)\n",
      "Step 50: loss = 2.73 (0.546 sec)\n",
      "Step 100: loss = 2.57 (0.551 sec)\n",
      "Step 150: loss = 1.89 (0.612 sec)\n",
      "Step 200: loss = 1.22 (0.720 sec)\n",
      "Step 250: loss = 1.10 (0.717 sec)\n",
      "Step 300: loss = 0.94 (0.748 sec)\n",
      "Step 350: loss = 0.92 (0.725 sec)\n",
      "Step 400: loss = 0.66 (0.706 sec)\n",
      "Step 450: loss = 0.58 (0.723 sec)\n",
      "Step 500: loss = 0.58 (0.799 sec)\n",
      "Step 550: loss = 0.57 (0.919 sec)\n",
      "Step 600: loss = 0.61 (0.703 sec)\n",
      "Step 650: loss = 0.42 (0.704 sec)\n",
      "Step 700: loss = 0.34 (0.700 sec)\n",
      "Step 750: loss = 0.40 (0.749 sec)\n",
      "Step 800: loss = 0.38 (1.675 sec)\n",
      "Step 850: loss = 0.35 (0.676 sec)\n",
      "Step 900: loss = 0.37 (0.709 sec)\n",
      "Step 950: loss = 0.21 (0.689 sec)\n",
      "Training Data Eval:\n",
      "  Num examples: 3200  Num correct: 2993  Precision @ 1: 0.9353\n",
      "Test Data Eval:\n",
      "  Num examples: 1600  Num correct: 1232  Precision @ 1: 0.7700\n",
      "Step 1000: loss = 0.19 (0.907 sec)\n",
      "Step 1050: loss = 0.23 (0.828 sec)\n",
      "Step 1100: loss = 0.18 (0.746 sec)\n",
      "Step 1150: loss = 0.16 (0.733 sec)\n",
      "Step 1200: loss = 0.14 (0.814 sec)\n",
      "Step 1250: loss = 0.17 (0.716 sec)\n",
      "Step 1300: loss = 0.11 (0.699 sec)\n",
      "Step 1350: loss = 0.14 (0.711 sec)\n",
      "Step 1400: loss = 0.09 (0.704 sec)\n",
      "Step 1450: loss = 0.09 (0.701 sec)\n",
      "Step 1500: loss = 0.08 (0.750 sec)\n",
      "Step 1550: loss = 0.06 (0.693 sec)\n",
      "Step 1600: loss = 0.10 (1.699 sec)\n",
      "Step 1650: loss = 0.04 (0.700 sec)\n",
      "Step 1700: loss = 0.07 (0.819 sec)\n",
      "Step 1750: loss = 0.08 (0.695 sec)\n",
      "Step 1800: loss = 0.05 (0.767 sec)\n",
      "Step 1850: loss = 0.09 (0.690 sec)\n",
      "Step 1900: loss = 0.07 (0.709 sec)\n",
      "Step 1950: loss = 0.05 (0.809 sec)\n",
      "Training Data Eval:\n",
      "  Num examples: 3200  Num correct: 3177  Precision @ 1: 0.9928\n",
      "Test Data Eval:\n",
      "  Num examples: 1600  Num correct: 1533  Precision @ 1: 0.9581\n",
      "Step 2000: loss = 0.04 (0.916 sec)\n",
      "Step 2050: loss = 0.03 (0.689 sec)\n",
      "Step 2100: loss = 0.02 (0.689 sec)\n",
      "Step 2150: loss = 0.02 (0.740 sec)\n",
      "Step 2200: loss = 0.04 (0.716 sec)\n",
      "Step 2250: loss = 0.02 (0.722 sec)\n",
      "Step 2300: loss = 0.07 (0.687 sec)\n",
      "Step 2350: loss = 0.03 (0.740 sec)\n",
      "Step 2400: loss = 0.02 (1.608 sec)\n",
      "Step 2450: loss = 0.01 (0.703 sec)\n",
      "Step 2500: loss = 0.02 (0.687 sec)\n",
      "Step 2550: loss = 0.01 (0.709 sec)\n",
      "Step 2600: loss = 0.02 (0.722 sec)\n",
      "Step 2650: loss = 0.01 (0.699 sec)\n",
      "Step 2700: loss = 0.01 (0.683 sec)\n",
      "Step 2750: loss = 0.01 (0.704 sec)\n",
      "Step 2800: loss = 0.02 (0.700 sec)\n",
      "Step 2850: loss = 0.01 (0.701 sec)\n",
      "Step 2900: loss = 0.03 (0.693 sec)\n",
      "Step 2950: loss = 0.01 (0.773 sec)\n",
      "Training Data Eval:\n",
      "  Num examples: 3200  Num correct: 3200  Precision @ 1: 1.0000\n",
      "Test Data Eval:\n",
      "  Num examples: 1600  Num correct: 1553  Precision @ 1: 0.9706\n",
      "Step 3000: loss = 0.01 (1.074 sec)\n",
      "Step 3050: loss = 0.01 (0.680 sec)\n",
      "Step 3100: loss = 0.02 (0.694 sec)\n",
      "Step 3150: loss = 0.01 (0.682 sec)\n",
      "Step 3200: loss = 0.01 (1.772 sec)\n",
      "Step 3250: loss = 0.01 (0.730 sec)\n",
      "Step 3300: loss = 0.01 (0.722 sec)\n",
      "Step 3350: loss = 0.00 (0.744 sec)\n",
      "Step 3400: loss = 0.01 (0.710 sec)\n",
      "Step 3450: loss = 0.01 (0.773 sec)\n",
      "Step 3500: loss = 0.01 (0.709 sec)\n",
      "Step 3550: loss = 0.01 (0.752 sec)\n",
      "Step 3600: loss = 0.01 (0.684 sec)\n",
      "Step 3650: loss = 0.01 (0.705 sec)\n",
      "Step 3700: loss = 0.01 (0.699 sec)\n",
      "Step 3750: loss = 0.01 (0.743 sec)\n",
      "Step 3800: loss = 0.01 (0.762 sec)\n",
      "Step 3850: loss = 0.01 (0.693 sec)\n",
      "Step 3900: loss = 0.01 (0.703 sec)\n",
      "Step 3950: loss = 0.00 (0.709 sec)\n",
      "Training Data Eval:\n",
      "  Num examples: 3200  Num correct: 3200  Precision @ 1: 1.0000\n",
      "Test Data Eval:\n",
      "  Num examples: 1600  Num correct: 1557  Precision @ 1: 0.9731\n"
     ]
    }
   ],
   "source": [
    "run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the training with cross-validation\n",
    "# run_training_with_cross_validation(k_folds=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
